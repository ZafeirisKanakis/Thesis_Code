{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model\n"
      ],
      "metadata": {
        "id": "eJgx0Aqvia8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIBhU2kqh19G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "ckpt_path = '/content/ckpt.pth'\n",
        "# ckpt_path = '/content/results/MVTecAD_Results/simplenet_mvtec/run/models/0/mvtec_floods/ckpt.pth'\n",
        "\n",
        "state_dict = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "\n",
        "print(\"Keys in checkpoint:\", state_dict.keys())\n",
        "\n",
        "in_planes = 1536\n",
        "#  def __init__(self, in_planes, n_layers=1, hidden=None):\n",
        "discriminator = Discriminator(in_planes=in_planes, n_layers=2, hidden=1024)\n",
        "# def __init__(self, in_planes, out_planes=None, n_layers=1, layer_type=0):\n",
        "projection = Projection(in_planes=in_planes, out_planes=1, n_layers=2)\n",
        "if \"discriminator\" in state_dict:\n",
        "    try:\n",
        "        discriminator_weights = state_dict[\"discriminator\"]\n",
        "        discriminator.load_state_dict(discriminator_weights)\n",
        "        print(\"Discriminator loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading discriminator weights: {e}\")\n",
        "else:\n",
        "    print(\"Discriminator weights not found in the checkpoint.\")\n",
        "\n",
        "discriminator.eval()\n",
        "\n",
        "# print('state_dict[projecction]', state_dict[\"pre_projection\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# t-SNE"
      ],
      "metadata": {
        "id": "JDogjdTnimVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "datapath = '/content/drive/MyDrive/mvtec_anomaly_detection'\n",
        "test_dataset = MVTecDataset(\n",
        "    source=datapath,\n",
        "    classname=\"floods\",\n",
        "    resize=329,\n",
        "    imagesize=288,\n",
        "    split=DatasetSplit.TEST,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "backbone = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True)\n",
        "layers_to_extract_from = ['layer4']\n",
        "input_shape = (3, 288, 288)\n",
        "pretrain_embed_dimension = 1536\n",
        "target_embed_dimension = 1536\n",
        "patchsize = 3\n",
        "patchstride = 1\n",
        "\n",
        "simplenet = SimpleNet(device)\n",
        "simplenet.load(\n",
        "    backbone=backbone,\n",
        "    layers_to_extract_from=layers_to_extract_from,\n",
        "    device=device,\n",
        "    input_shape=input_shape,\n",
        "    pretrain_embed_dimension=pretrain_embed_dimension,\n",
        "    target_embed_dimension=target_embed_dimension,\n",
        "    patchsize=patchsize,\n",
        "    patchstride=patchstride\n",
        ")\n",
        "simplenet.backbone.eval()\n",
        "\n",
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        images = batch[\"image\"].to(device)\n",
        "\n",
        "        batch_embeddings = simplenet.embed(images)\n",
        "\n",
        "        batch_embeddings = batch_embeddings[0]\n",
        "\n",
        "        print(f\"Batch embeddings shape: {batch_embeddings.shape}\")\n",
        "\n",
        "        batch_embeddings = batch_embeddings.cpu().numpy()\n",
        "        embeddings.append(batch_embeddings)\n",
        "\n",
        "        labels_batch = batch[\"is_anomaly\"].numpy()\n",
        "        print(f\"Labels batch shape: {labels_batch.shape}\")\n",
        "\n",
        "        labels.extend(batch[\"is_anomaly\"].cpu().numpy())\n",
        "\n",
        "embeddings = np.concatenate(embeddings, axis=0)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")\n",
        "print(f\"Labels length: {len(labels)}\")\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "reduced_embeddings = tsne.fit_transform(embeddings)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for label in np.unique(labels):\n",
        "    indices = np.where(labels == label)[0]\n",
        "\n",
        "    plt.scatter(\n",
        "        reduced_embeddings[indices, 0],\n",
        "        reduced_embeddings[indices, 1],\n",
        "        label=f\"{'Anomalous' if label else 'Normal'}\",\n",
        "        alpha=0.6,\n",
        "    )\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"t-SNE of Feature Embeddings\")\n",
        "plt.xlabel(\"t-SNE Dimension 1\")\n",
        "plt.ylabel(\"t-SNE Dimension 2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OJftIsioieKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anomaly Maps Generation"
      ],
      "metadata": {
        "id": "acWK-9jVi2BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "simplenet = SimpleNet(device)\n",
        "simplenet.load(\n",
        "    backbone=backbone,\n",
        "    layers_to_extract_from=layers_to_extract_from,\n",
        "    device=device,\n",
        "    input_shape=input_shape,\n",
        "    pretrain_embed_dimension=pretrain_embed_dimension,\n",
        "    target_embed_dimension=target_embed_dimension,\n",
        "    patchsize=patchsize,\n",
        "    patchstride=patchstride,\n",
        ")\n",
        "simplenet.backbone.eval()\n",
        "\n",
        "def normalize_mask(mask):\n",
        "    \"\"\"Normalize mask to range [0, 1].\"\"\"\n",
        "    return (mask - np.min(mask)) / (np.max(mask) - np.min(mask) + 1e-8)\n",
        "\n",
        "def generate_anomaly_maps(simplenet, dataloader):\n",
        "    scores = []\n",
        "    masks = []\n",
        "    img_paths = []\n",
        "    labels_gt = []\n",
        "    masks_gt = []\n",
        "\n",
        "    simplenet.backbone.eval()\n",
        "\n",
        "    with tqdm(dataloader, desc=\"Generating Anomaly Maps\", leave=False) as data_iterator:\n",
        "        for data in data_iterator:\n",
        "            images = data[\"image\"].to(device)\n",
        "            img_paths.extend(data[\"image_path\"])\n",
        "\n",
        "            labels_gt.extend(data[\"is_anomaly\"].cpu().numpy().tolist())\n",
        "            if data.get(\"mask\", None) is not None:\n",
        "                masks_gt.extend(data[\"mask\"].cpu().numpy().tolist())\n",
        "\n",
        "            _scores, _masks, _feats = simplenet._predict(images)\n",
        "            scores.extend(_scores)\n",
        "            masks.extend(_masks)\n",
        "\n",
        "    return scores, masks, img_paths, labels_gt, masks_gt\n",
        "\n",
        "scores, masks, img_paths, labels_gt, masks_gt = generate_anomaly_maps(simplenet, test_loader)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_binary_masks(masks):\n",
        "    \"\"\"\n",
        "    Plots the binary masks where:\n",
        "    - Values < 0.5 are black\n",
        "    - Values >= 0.5 are white\n",
        "\n",
        "    Args:\n",
        "    - masks (list of numpy arrays): List of normalized masks to plot.\n",
        "    \"\"\"\n",
        "    for i, mask in enumerate(masks):\n",
        "        # Threshold the mask to binary values: 0 for black, 1 for white\n",
        "        binary_mask = np.where(mask >= 0.5, 1.0, 0.0)\n",
        "\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        plt.title(f\"Binary Mask {i + 1}\")\n",
        "        plt.imshow(binary_mask, cmap='gray')  # 'gray' colormap for black/white\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# def print_normalized_masks(masks, num_to_print=5):\n",
        "#     \"\"\"\n",
        "#     Prints the normalized values of the first few anomaly masks.\n",
        "\n",
        "#     Args:\n",
        "#     - masks (list): List of masks (numpy arrays).\n",
        "#     - num_to_print (int): Number of masks to print.\n",
        "#     \"\"\"\n",
        "#     print(\"Normalized Anomaly Masks (Numerical Values):\")\n",
        "#     for i, mask in enumerate(masks[:num_to_print]):\n",
        "#         # normalized_mask = normalize_mask(mask)  # Normalize the mask\n",
        "#         print(f\"\\nMask {i + 1}:\")\n",
        "#         print(normalized_mask)\n",
        "\n",
        "\n",
        "# pred_binary_masks2 = []\n",
        "# for i, (image_path, mask) in enumerate(zip(img_paths[:5], masks[:5])):\n",
        "#     normalized_mask = normalize_mask(mask)\n",
        "#     plot_binary_masks([normalized_mask])\n",
        "#     # Threshold the anomaly map for binary visualization\n",
        "#     binary_mask_pred = np.where(normalized_mask > 0.5, 0.0, 1.0)\n",
        "#     pred_binary_masks2.append(binary_mask_pred)\n",
        "\n",
        "#     plt.figure(figsize=(15, 5))\n",
        "\n",
        "#     plt.subplot(1, 3, 1)\n",
        "#     plt.title(\"Original Image\")\n",
        "#     plt.imshow(plt.imread(image_path))\n",
        "#     plt.axis(\"off\")\n",
        "\n",
        "#     plt.subplot(1, 3, 2)\n",
        "#     plt.title(\"Normalized Anomaly Map\")\n",
        "#     plt.imshow(normalized_mask, cmap=\"hot\")\n",
        "#     plt.axis(\"off\")\n",
        "\n",
        "#     plt.subplot(1, 3, 3)\n",
        "#     plt.title(\"Overlayed Anomaly Map\")\n",
        "#     plt.imshow(plt.imread(image_path), alpha=0.6)\n",
        "#     plt.imshow(normalized_mask, cmap=\"jet\", alpha=0.4)\n",
        "#     plt.axis(\"off\")\n",
        "\n",
        "#     plt.show()\n",
        "\n",
        "\n",
        "num_images_to_plot = 5\n",
        "\n",
        "pred_binary_masks2 = []\n",
        "for i, (image_path, mask) in enumerate(zip(img_paths[:num_images_to_plot], masks[:num_images_to_plot])):\n",
        "    normalized_mask = normalize_mask(mask)\n",
        "    plot_binary_masks([normalized_mask])\n",
        "    binary_mask_pred = np.where(normalized_mask > 0.5, 0.0, 1.0)\n",
        "    pred_binary_masks2.append(binary_mask_pred)\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.imshow(plt.imread(image_path))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(\"Normalized Anomaly Map\")\n",
        "    plt.imshow(normalized_mask, cmap=\"hot\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"Overlayed Anomaly Map\")\n",
        "    plt.imshow(plt.imread(image_path), alpha=0.6)\n",
        "    plt.imshow(normalized_mask, cmap=\"jet\", alpha=0.4)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "I21UgDBni0km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dice Coefficient\n",
        "## Load Ground Truth Files"
      ],
      "metadata": {
        "id": "KJBjO5cJjJk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_ground_truth_images(image_paths):\n",
        "\n",
        "    numpy_arrays = []\n",
        "    for path in image_paths:\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"Warning: File not found - {path}\")\n",
        "            continue\n",
        "\n",
        "        img = Image.open(path).convert(\"L\")\n",
        "\n",
        "        img_array = np.array(img)\n",
        "        numpy_arrays.append(img_array)\n",
        "\n",
        "    return numpy_arrays\n",
        "\n",
        "def plot_images(image_arrays, titles=None):\n",
        "    \"\"\"\n",
        "    Plots a list of images using Matplotlib.\n",
        "\n",
        "    Args:\n",
        "    - image_arrays (list of np.array): List of image arrays.\n",
        "    - titles (list of str, optional): Titles for each image plot.\n",
        "    \"\"\"\n",
        "    num_images = len(image_arrays)\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    for i, img_array in enumerate(image_arrays):\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(img_array, cmap='gray')\n",
        "        title = titles[i] if titles else f\"Image {i + 1}\"\n",
        "        plt.title(title)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "path = \"/content/drive/MyDrive/mvtec_anomaly_detection/floods/ground_truth/floods/\"\n",
        "image_names = [\n",
        "    \"EMSR260_02VIADANA.png\",\n",
        "    \"EMSR271_02FARKADONA.png\",\n",
        "    \"EMSR324_04LESPIGNAN.png\",\n",
        "    \"EMSR333_02PORTOPALO.png\"\n",
        "]\n",
        "image_paths = [os.path.join(path, img_name) for img_name in image_names]\n",
        "\n",
        "ground_truth_arrays = load_ground_truth_images(image_paths)\n",
        "plot_images(ground_truth_arrays, titles=image_names)\n"
      ],
      "metadata": {
        "id": "wYbqbGxpjhbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3cbS_745j7lB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "import cv2\n",
        "\n",
        "def dice_coefficient(mask1, mask2):\n",
        "    mask1 = (mask1 > 0).astype(np.float32)\n",
        "    mask2 = (mask2 > 0).astype(np.float32)\n",
        "\n",
        "    if mask1.shape != mask2.shape:\n",
        "        mask1 = cv2.resize(mask1, (mask2.shape[1], mask2.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    intersection = np.sum(mask1 * mask2)\n",
        "    dice = (2.0 * intersection) / (np.sum(mask1) + np.sum(mask2) + 1e-8)\n",
        "\n",
        "    return dice\n",
        "\n",
        "for idx, (binary_mask_pred, binary_mask_gt, arr) in enumerate(zip(pred_binary_masks, pred_binary_masks2, ground_truth_arrays)):\n",
        "    dice_score = dice_coefficient(binary_mask_pred, binary_mask_gt)\n",
        "\n",
        "    print(f\"Dice Coefficient for image {idx + 1}: {dice_score:.4f}\")"
      ],
      "metadata": {
        "id": "DyIhVJ3hj6vX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}